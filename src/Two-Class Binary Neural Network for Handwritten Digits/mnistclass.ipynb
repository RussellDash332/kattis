{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "_=files.upload() # upload mnist2_train.txt and mnist10_train.txt"
      ],
      "metadata": {
        "id": "g5p-rjhFtDrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install larq"
      ],
      "metadata": {
        "id": "irRDmQOUx6OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import larq as lq"
      ],
      "metadata": {
        "id": "HW3VvUQidcOZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(BITS, CLASSES, validation_split=0.3, epochs=25, learning_rate=1e-4, patience=3, **kwargs):\n",
        "    X, y = [], []\n",
        "    with open(f'mnist{CLASSES}_train.txt', 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            *a, b = map(int, line.split())\n",
        "            X.append(a), y.append(b)\n",
        "    X, y = map(np.array, (X, y))\n",
        "    def kinit(shape, dtype=None):\n",
        "        arr = np.zeros(shape)\n",
        "        for i in range(shape[0]): arr[i][i//15] = 1\n",
        "        return tf.convert_to_tensor(arr, dtype=dtype)\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(\n",
        "        lq.layers.QuantDense(\n",
        "            15*CLASSES,\n",
        "            input_quantizer=lq.quantizers.SteSign(clip_value=1.0),\n",
        "            #input_quantizer=lq.quantizers.NoOp(precision=1),\n",
        "            kernel_quantizer=lq.quantizers.SteSign(clip_value=1.0),\n",
        "            #kernel_quantizer=lq.quantizers.NoOp(precision=1),\n",
        "            kernel_constraint=lq.constraints.WeightClip(clip_value=1),\n",
        "            input_shape=(BITS,),\n",
        "            use_bias=False\n",
        "        )\n",
        "    )\n",
        "    model.add(tf.keras.layers.Dense(CLASSES, kernel_initializer=kinit, use_bias=False, trainable=False))\n",
        "    model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "    model.add(tf.keras.layers.Activation(\"softmax\"))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(X, y, validation_split=validation_split, epochs=epochs, callbacks=[tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=patience)], **kwargs)\n",
        "    t = [[int(s) for s in r] for r in lq.math.sign(model.weights[0])]\n",
        "    w = [[t[i][j] for i in range(BITS)] for j in range(15*CLASSES)]\n",
        "    print(f\"for r in{str(w).replace(' ','').replace('[','(').replace(']',')')}:print(*r)\")"
      ],
      "metadata": {
        "id": "ZRIkV5CTc0M4"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST 10 class\n",
        "train(BITS=51, CLASSES=10, validation_split=0.0, epochs=250, learning_rate=9e-4, patience=17, steps_per_epoch=800)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Yc05rZ7dvcV",
        "outputId": "47c47e6c-784f-4f48-df55-b4a695910edd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.0969 - accuracy: 0.7550\n",
            "Epoch 2/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0044 - accuracy: 0.7946\n",
            "Epoch 3/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0033 - accuracy: 0.7964\n",
            "Epoch 4/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0010 - accuracy: 0.7966\n",
            "Epoch 5/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0014 - accuracy: 0.7958\n",
            "Epoch 6/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0010 - accuracy: 0.7964\n",
            "Epoch 7/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0024 - accuracy: 0.7968\n",
            "Epoch 8/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0021 - accuracy: 0.7971\n",
            "Epoch 9/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0010 - accuracy: 0.7970\n",
            "Epoch 10/250\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.0024 - accuracy: 0.7965\n",
            "Epoch 11/250\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.0024 - accuracy: 0.7955\n",
            "Epoch 12/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0015 - accuracy: 0.7981\n",
            "Epoch 13/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0026 - accuracy: 0.7950\n",
            "Epoch 14/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0010 - accuracy: 0.7951\n",
            "Epoch 15/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0011 - accuracy: 0.7978\n",
            "Epoch 16/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0012 - accuracy: 0.7969\n",
            "Epoch 17/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0003 - accuracy: 0.7970\n",
            "Epoch 18/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0028 - accuracy: 0.7951\n",
            "Epoch 19/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0019 - accuracy: 0.7968\n",
            "Epoch 20/250\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.0007 - accuracy: 0.7968\n",
            "Epoch 21/250\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.0022 - accuracy: 0.7970\n",
            "Epoch 22/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0014 - accuracy: 0.7971\n",
            "Epoch 23/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0028 - accuracy: 0.7971\n",
            "Epoch 24/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0021 - accuracy: 0.7976\n",
            "Epoch 25/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0019 - accuracy: 0.7958\n",
            "Epoch 26/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0019 - accuracy: 0.7953\n",
            "Epoch 27/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0028 - accuracy: 0.7961\n",
            "Epoch 28/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0029 - accuracy: 0.7970\n",
            "Epoch 29/250\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0022 - accuracy: 0.7958\n",
            "for r in((1,1,1,-1,1,-1,-1,1,1,1,1,1,-1,-1,1,-1,-1,1,1,-1,1,1,1,1,-1,1,-1,1,1,-1,1,-1,1,-1,1,-1,-1,1,1,-1,1,-1,-1,-1,-1,1,-1,-1,1,1,-1),(1,1,1,-1,1,-1,-1,-1,1,1,1,1,-1,-1,1,1,-1,1,1,-1,1,1,1,-1,1,1,1,1,-1,-1,1,-1,1,1,1,-1,1,1,-1,1,1,-1,-1,1,1,-1,-1,1,-1,-1,-1),(-1,-1,1,-1,1,-1,-1,-1,1,1,-1,-1,1,1,1,1,1,-1,1,-1,1,1,1,-1,-1,1,1,1,-1,-1,-1,1,1,1,-1,1,1,1,1,-1,1,1,1,1,1,-1,-1,-1,1,1,1),(1,1,-1,-1,1,-1,-1,-1,1,-1,1,1,-1,-1,-1,-1,1,-1,1,-1,1,1,1,1,-1,1,1,-1,-1,-1,-1,1,1,1,1,1,1,1,-1,-1,1,1,1,1,1,-1,-1,-1,1,1,-1),(1,1,1,-1,-1,-1,-1,-1,1,1,1,1,-1,-1,1,-1,1,-1,1,-1,1,1,-1,-1,1,1,-1,-1,1,-1,1,-1,1,1,-1,-1,1,1,-1,-1,1,1,1,-1,-1,1,-1,-1,-1,-1,-1),(1,-1,1,-1,1,-1,-1,-1,1,1,-1,1,-1,-1,-1,1,-1,-1,1,1,-1,-1,1,-1,-1,-1,-1,1,-1,-1,1,-1,1,1,1,1,1,-1,1,-1,1,1,1,-1,1,1,-1,1,1,1,1),(1,1,-1,-1,1,-1,-1,1,1,-1,1,-1,-1,1,1,-1,1,-1,1,-1,-1,1,1,1,1,1,-1,1,-1,-1,1,1,1,1,1,-1,1,-1,-1,1,1,1,1,-1,1,-1,-1,1,1,-1,1),(1,1,-1,-1,1,-1,-1,1,1,1,1,1,1,-1,-1,-1,-1,-1,1,1,1,1,-1,-1,1,1,1,1,1,-1,1,-1,1,1,-1,-1,1,1,-1,-1,1,1,1,1,1,1,-1,-1,-1,1,-1),(1,1,1,-1,1,-1,-1,-1,1,1,-1,1,1,-1,1,-1,-1,-1,1,-1,-1,1,-1,1,-1,1,-1,-1,-1,-1,1,1,-1,1,1,1,1,1,1,-1,1,1,1,-1,1,-1,-1,1,-1,1,-1),(1,1,1,-1,1,-1,-1,1,1,1,-1,-1,-1,1,1,-1,1,1,1,1,1,1,-1,1,-1,1,-1,-1,-1,-1,1,1,1,1,1,1,1,1,-1,1,1,1,1,1,1,-1,-1,-1,-1,-1,-1),(1,1,1,-1,1,-1,-1,1,1,1,-1,-1,-1,1,1,-1,-1,1,1,-1,1,-1,-1,-1,1,1,-1,-1,-1,-1,1,-1,-1,1,1,1,1,1,1,1,1,1,1,-1,1,-1,-1,-1,-1,1,-1),(1,-1,1,-1,1,-1,-1,-1,1,-1,-1,1,-1,1,-1,-1,-1,-1,1,-1,1,1,-1,-1,1,1,1,1,-1,-1,1,-1,1,-1,1,-1,1,1,-1,-1,1,1,-1,1,1,1,-1,1,-1,-1,1),(1,1,-1,-1,1,-1,-1,1,1,1,1,1,-1,1,-1,1,1,1,1,-1,1,1,-1,-1,-1,1,-1,1,1,-1,1,-1,1,1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,1,-1,-1,-1,1,1),(1,-1,1,-1,1,-1,-1,1,1,-1,-1,-1,-1,-1,-1,1,-1,-1,1,-1,-1,-1,-1,1,1,-1,1,1,-1,-1,-1,1,1,1,-1,1,1,-1,1,1,1,-1,-1,1,1,1,-1,-1,1,-1,-1),(1,-1,-1,-1,1,-1,-1,-1,1,-1,1,-1,1,-1,1,1,-1,-1,1,1,1,-1,1,1,1,1,1,-1,-1,-1,1,-1,1,-1,-1,1,-1,1,-1,1,1,1,-1,-1,1,-1,-1,1,-1,1,1),(-1,-1,1,1,-1,1,-1,-1,1,1,-1,-1,1,-1,-1,-1,-1,-1,-1,-1,1,-1,1,-1,-1,-1,-1,-1,-1,-1,-1,-1,1,-1,1,1,-1,-1,-1,-1,-1,1,1,-1,-1,-1,1,1,-1,-1,1),(-1,-1,-1,1,1,1,-1,-1,-1,-1,1,1,-1,-1,-1,-1,1,-1,-1,-1,-1,-1,1,-1,1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1,1,-1,-1,1,1,1,1,-1,1,1,1,1,1,1),(1,-1,1,1,-1,1,-1,-1,1,1,1,1,-1,-1,1,-1,-1,-1,-1,-1,-1,1,1,1,-1,-1,-1,-1,1,-1,-1,-1,1,-1,-1,-1,-1,-1,-1,1,1,1,-1,-1,-1,1,1,-1,1,-1,1),(1,-1,-1,1,1,1,-1,-1,-1,-1,1,-1,-1,-1,-1,-1,-1,1,-1,-1,1,1,1,1,1,-1,1,-1,-1,-1,1,-1,1,1,-1,-1,1,-1,-1,-1,-1,-1,1,-1,-1,1,1,1,1,-1,1),(1,-1,-1,1,1,1,-1,-1,1,-1,-1,-1,-1,-1,-1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,-1,-1,1,-1,1,-1,1,1,-1,-1,-1,-1,-1,-1,-1,-1,1,1,1,-1,1,1,1,-1,-1),(-1,1,-1,1,-1,1,1,-1,1,-1,-1,1,-1,1,-1,-1,1,-1,-1,-1,-1,-1,1,1,1,-1,1,-1,-1,-1,1,1,1,1,-1,1,-1,-1,1,-1,-1,-1,1,1,-1,-1,1,-1,-1,-1,-1),(-1,1,1,1,-1,1,-1,1,-1,1,1,-1,-1,-1,1,-1,-1,-1,-1,-1,-1,1,1,-1,1,1,1,-1,-1,-1,1,-1,-1,-1,-1,-1,1,-1,-1,-1,1,-1,1,-1,-1,1,1,1,-1,1,-1),(1,-1,1,-1,1,1,1,1,-1,1,1,-1,1,1,-1,-1,-1,1,1,-1,1,-1,1,-1,-1,-1,-1,1,-1,-1,-1,1,1,1,-1,-1,-1,-1,-1,-1,-1,-1,1,-1,-1,1,1,-1,1,-1,1),(-1,1,1,1,-1,1,-1,1,-1,-1,-1,1,-1,-1,1,-1,-1,-1,1,-1,1,1,1,1,1,1,-1,-1,1,-1,-1,-1,-1,-1,1,1,1,-1,-1,1,-1,1,1,1,-1,1,1,-1,-1,-1,1),(-1,-1,-1,-1,1,1,-1,1,1,1,-1,1,-1,-1,1,-1,1,-1,1,-1,1,-1,1,-1,1,1,1,-1,-1,-1,1,1,-1,-1,-1,-1,-1,-1,1,-1,-1,-1,1,-1,1,1,1,1,-1,-1,-1),(-1,-1,1,1,-1,1,-1,1,1,1,1,1,-1,1,1,-1,-1,-1,1,-1,1,-1,1,-1,1,-1,1,-1,-1,1,-1,-1,-1,1,1,-1,1,1,-1,1,-1,1,-1,1,-1,1,1,-1,1,-1,1),(1,-1,-1,1,-1,1,-1,-1,1,1,-1,1,1,-1,-1,-1,-1,1,-1,-1,1,1,1,1,1,1,-1,1,-1,-1,-1,-1,-1,1,-1,1,1,-1,1,-1,1,-1,1,-1,1,-1,1,-1,1,-1,-1),(-1,1,1,-1,-1,1,-1,-1,1,-1,1,1,-1,1,1,-1,1,-1,-1,-1,1,-1,1,-1,-1,1,1,-1,-1,1,-1,1,1,1,1,1,1,1,1,-1,-1,1,-1,-1,-1,-1,1,1,-1,-1,-1),(1,-1,-1,1,1,1,-1,1,1,-1,1,1,-1,-1,-1,-1,-1,1,1,-1,1,-1,1,1,1,1,1,-1,1,-1,1,-1,1,1,-1,-1,1,-1,1,-1,-1,1,1,-1,1,1,1,-1,-1,-1,-1),(1,-1,-1,1,1,1,-1,-1,1,-1,-1,-1,-1,1,-1,1,1,-1,1,-1,1,1,1,-1,-1,1,1,-1,-1,-1,-1,-1,-1,-1,-1,1,-1,-1,1,-1,1,-1,-1,-1,1,1,1,-1,-1,1,-1),(1,-1,-1,-1,-1,-1,1,1,-1,-1,1,1,1,1,1,1,-1,1,1,1,-1,1,-1,1,1,-1,-1,-1,1,1,1,-1,1,1,1,-1,-1,1,1,1,-1,1,1,-1,-1,1,-1,1,-1,-1,-1),(-1,1,-1,1,-1,1,1,-1,-1,-1,1,-1,-1,1,1,-1,-1,1,1,1,-1,1,1,1,-1,-1,-1,1,1,-1,1,-1,1,1,-1,-1,-1,1,1,-1,-1,1,1,1,-1,1,-1,-1,-1,-1,-1),(-1,-1,1,-1,-1,1,1,-1,-1,1,1,1,1,-1,1,1,-1,1,-1,1,-1,1,-1,-1,1,-1,1,-1,-1,-1,1,1,1,-1,-1,1,-1,1,1,1,-1,-1,1,-1,-1,1,-1,1,-1,-1,1),(-1,1,1,1,-1,1,-1,-1,-1,1,1,1,-1,1,1,-1,-1,1,1,1,-1,-1,1,1,-1,1,1,-1,1,-1,-1,1,-1,1,1,-1,-1,1,1,1,1,-1,-1,1,1,1,-1,1,-1,-1,-1),(-1,-1,-1,-1,-1,1,-1,-1,-1,1,1,1,1,-1,1,1,-1,-1,1,1,-1,-1,1,1,-1,-1,-1,-1,1,1,1,1,1,1,-1,-1,-1,1,1,-1,1,1,1,1,1,-1,-1,-1,-1,-1,-1),(-1,1,1,1,-1,1,-1,1,-1,-1,1,1,-1,1,1,1,-1,1,1,1,-1,1,-1,-1,-1,-1,1,-1,1,1,-1,1,-1,1,-1,1,-1,1,1,-1,-1,1,1,1,1,1,-1,1,1,-1,-1),(-1,1,1,1,-1,1,-1,-1,-1,1,1,-1,-1,-1,1,1,-1,1,1,1,-1,-1,-1,1,1,-1,-1,-1,-1,1,-1,-1,1,-1,-1,1,1,1,1,1,1,-1,1,-1,1,-1,1,-1,-1,-1,-1),(-1,1,-1,-1,-1,1,1,1,-1,1,-1,-1,1,1,1,-1,-1,-1,1,1,-1,1,-1,1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,-1,-1,1,1,1,-1,1,1,1,-1,1,-1,1,-1,-1,1),(-1,1,1,-1,-1,1,1,1,-1,1,-1,-1,1,1,1,1,-1,1,1,1,-1,1,-1,1,-1,-1,-1,-1,1,-1,1,-1,-1,-1,1,1,-1,1,1,-1,-1,-1,-1,-1,1,1,1,-1,1,-1,1),(-1,1,-1,-1,-1,-1,1,1,-1,-1,1,1,-1,1,1,1,-1,-1,1,1,1,-1,-1,-1,-1,-1,-1,-1,-1,1,-1,-1,1,1,1,1,-1,1,1,-1,1,-1,-1,1,-1,-1,-1,-1,1,-1,1),(-1,1,-1,1,-1,1,1,1,-1,1,-1,1,-1,1,-1,-1,-1,1,1,1,1,1,-1,1,1,-1,1,1,-1,1,-1,-1,-1,-1,-1,-1,-1,1,1,-1,1,1,-1,-1,1,-1,1,1,-1,1,1),(-1,-1,1,-1,-1,1,-1,-1,-1,1,1,1,1,1,1,-1,-1,1,1,1,-1,-1,1,1,1,-1,-1,-1,-1,-1,1,1,-1,1,1,1,1,1,-1,-1,-1,-1,-1,1,1,1,-1,1,-1,1,1),(-1,1,-1,-1,-1,1,1,1,-1,1,-1,1,1,-1,1,1,-1,1,1,1,1,1,-1,-1,1,-1,1,-1,-1,1,1,1,1,-1,1,1,-1,1,1,1,1,1,1,1,1,-1,-1,-1,-1,-1,1),(-1,-1,1,1,-1,-1,1,1,-1,1,-1,1,1,1,1,1,-1,-1,-1,1,-1,-1,-1,-1,-1,-1,1,-1,-1,1,-1,-1,1,1,1,-1,-1,1,1,-1,1,1,-1,-1,1,1,-1,1,-1,-1,1),(-1,-1,1,-1,-1,1,1,-1,-1,-1,-1,1,-1,1,1,-1,-1,-1,1,1,1,1,1,-1,-1,-1,-1,1,1,-1,1,-1,-1,-1,-1,1,1,1,1,1,-1,1,-1,-1,1,1,-1,-1,-1,-1,-1),(1,1,1,-1,-1,-1,-1,-1,1,1,1,-1,-1,1,1,1,-1,-1,1,1,-1,1,1,1,-1,1,1,-1,1,1,1,-1,-1,1,-1,-1,1,1,1,-1,-1,-1,-1,1,-1,1,1,-1,-1,1,1),(-1,1,-1,1,-1,-1,1,-1,-1,-1,1,-1,1,1,1,-1,1,-1,1,1,-1,-1,1,1,-1,-1,-1,-1,-1,1,-1,-1,-1,-1,1,1,1,1,-1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,1),(1,1,1,-1,-1,-1,1,1,-1,1,-1,-1,1,-1,1,1,1,-1,1,1,1,-1,1,1,1,-1,1,-1,1,1,1,-1,1,-1,1,-1,-1,-1,-1,1,-1,-1,-1,1,-1,1,1,-1,-1,-1,-1),(1,1,1,-1,-1,-1,1,-1,1,-1,-1,-1,1,1,1,1,-1,-1,-1,1,1,1,1,1,1,-1,1,-1,1,1,-1,1,1,1,1,-1,-1,1,1,-1,-1,1,-1,1,-1,1,1,1,-1,-1,-1),(1,1,-1,1,-1,-1,-1,1,-1,1,-1,-1,1,-1,1,1,1,-1,-1,1,1,-1,1,1,-1,-1,1,-1,1,1,1,-1,1,1,1,-1,-1,-1,1,1,1,-1,-1,1,-1,-1,1,1,-1,1,-1),(1,-1,-1,1,-1,-1,1,1,1,1,1,-1,1,1,1,-1,1,-1,1,1,-1,1,-1,1,-1,1,1,-1,1,1,1,1,1,1,1,-1,1,-1,1,-1,-1,-1,1,1,-1,-1,1,-1,-1,-1,-1),(1,1,1,1,-1,-1,1,1,-1,1,-1,-1,1,1,1,-1,-1,-1,1,1,-1,1,1,1,1,-1,1,-1,1,1,1,-1,-1,-1,1,1,1,-1,1,-1,-1,-1,1,1,1,-1,1,1,-1,1,1),(-1,1,1,-1,-1,-1,-1,1,1,1,1,-1,1,-1,1,-1,1,-1,1,1,1,1,1,1,-1,1,-1,-1,-1,1,1,1,1,-1,1,1,1,-1,1,-1,-1,-1,1,1,-1,1,1,1,-1,1,1),(1,-1,1,1,-1,-1,-1,1,1,1,1,-1,1,1,1,1,1,-1,1,1,-1,1,1,1,-1,1,1,-1,-1,-1,1,-1,1,1,-1,-1,1,-1,-1,1,1,1,-1,1,-1,1,1,-1,-1,1,-1),(1,1,1,1,-1,-1,1,1,1,-1,-1,-1,1,1,1,1,-1,-1,-1,1,1,1,1,1,1,-1,-1,-1,1,1,-1,-1,1,1,1,-1,-1,1,-1,-1,-1,-1,-1,-1,-1,-1,1,1,-1,-1,1),(1,1,-1,-1,-1,-1,1,1,1,1,-1,-1,1,1,1,1,1,1,-1,1,1,-1,1,1,1,-1,-1,-1,1,-1,1,-1,-1,1,-1,1,1,-1,-1,-1,1,-1,1,-1,-1,-1,1,1,-1,-1,-1),(-1,1,1,-1,-1,-1,-1,-1,-1,1,1,-1,1,1,1,1,1,-1,-1,1,-1,1,1,-1,1,-1,1,-1,1,-1,-1,1,-1,1,1,1,-1,-1,1,-1,1,1,-1,1,-1,-1,1,-1,-1,-1,1),(1,1,1,1,-1,-1,-1,-1,-1,-1,1,-1,1,1,1,1,-1,-1,-1,1,-1,1,1,1,-1,-1,-1,-1,1,1,1,-1,-1,1,1,-1,-1,1,1,-1,1,1,1,1,-1,1,1,-1,-1,-1,-1),(1,1,1,-1,-1,-1,1,1,-1,-1,-1,-1,1,1,1,1,1,-1,-1,1,1,1,1,1,1,1,1,-1,1,1,-1,-1,1,-1,1,1,-1,1,-1,-1,1,-1,-1,-1,-1,-1,1,1,-1,1,1),(1,1,1,1,-1,-1,-1,1,-1,-1,1,-1,1,-1,1,-1,-1,-1,-1,1,1,1,1,1,1,-1,-1,-1,1,1,-1,-1,-1,1,1,-1,1,-1,1,1,-1,-1,-1,1,-1,-1,1,1,-1,1,1),(-1,-1,-1,1,1,1,1,1,-1,-1,-1,-1,-1,-1,1,1,1,1,-1,1,-1,-1,1,1,-1,1,1,-1,-1,1,1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,1,1,-1,1,-1,1,-1,1,1,-1),(-1,-1,-1,1,1,1,1,-1,-1,1,1,-1,-1,-1,-1,1,1,1,-1,1,-1,-1,-1,-1,1,-1,-1,-1,-1,1,1,1,-1,-1,-1,-1,-1,-1,-1,1,-1,1,1,-1,1,-1,1,-1,-1,1,-1),(1,1,1,1,1,-1,1,-1,-1,1,1,-1,-1,-1,-1,-1,1,1,-1,-1,-1,-1,-1,-1,-1,1,1,1,-1,-1,-1,1,-1,-1,1,-1,-1,-1,-1,-1,-1,1,1,1,-1,-1,-1,1,-1,1,-1),(-1,1,-1,-1,-1,-1,1,-1,-1,-1,1,-1,1,1,-1,1,1,1,-1,-1,1,-1,-1,-1,-1,1,1,-1,-1,1,-1,-1,-1,-1,1,-1,1,-1,-1,-1,1,1,-1,-1,-1,-1,-1,1,-1,1,-1),(-1,-1,1,1,1,-1,1,-1,-1,-1,1,-1,1,-1,-1,1,-1,1,-1,1,1,-1,-1,1,1,1,1,1,-1,1,-1,-1,-1,1,-1,-1,1,-1,-1,1,1,1,-1,-1,1,1,-1,1,-1,1,1),(-1,1,-1,1,1,1,1,1,-1,-1,-1,-1,1,1,-1,1,-1,1,1,-1,-1,-1,-1,-1,-1,1,1,-1,1,1,1,1,-1,1,1,-1,-1,1,-1,-1,1,1,1,1,-1,-1,-1,1,1,1,-1),(1,1,-1,-1,1,1,-1,1,-1,-1,-1,-1,1,1,-1,-1,-1,1,-1,1,1,-1,1,-1,-1,1,-1,-1,-1,-1,1,-1,-1,1,-1,1,1,1,1,1,1,1,1,1,-1,-1,-1,1,1,1,-1),(1,-1,1,1,1,1,-1,-1,-1,-1,-1,-1,1,-1,-1,1,-1,1,1,-1,-1,-1,1,-1,-1,1,1,1,-1,-1,-1,1,1,1,-1,-1,-1,-1,-1,1,-1,1,-1,-1,1,-1,1,1,1,1,-1),(-1,-1,-1,1,1,1,1,-1,-1,-1,1,-1,-1,1,1,-1,1,-1,-1,1,1,-1,1,1,1,1,1,1,-1,-1,1,-1,-1,-1,-1,-1,1,1,-1,-1,1,1,1,-1,1,-1,1,1,-1,1,-1),(-1,1,1,-1,1,1,1,-1,-1,1,-1,-1,1,-1,1,-1,1,1,-1,-1,1,-1,-1,1,1,1,-1,1,-1,1,1,-1,-1,-1,-1,-1,1,-1,-1,1,1,1,1,1,-1,-1,1,1,1,-1,-1),(1,1,-1,1,1,1,1,-1,-1,-1,1,-1,1,1,1,-1,1,1,-1,-1,1,-1,1,-1,1,1,-1,1,-1,1,-1,-1,-1,1,1,1,-1,-1,-1,1,-1,1,1,1,-1,-1,-1,1,1,1,1),(-1,1,-1,1,1,1,1,-1,-1,-1,-1,-1,1,1,1,1,1,-1,-1,1,-1,-1,-1,-1,-1,1,-1,-1,-1,1,-1,-1,-1,1,-1,-1,1,-1,-1,1,1,1,1,-1,-1,-1,1,-1,1,1,1),(-1,1,-1,-1,1,1,1,1,-1,1,-1,-1,1,1,1,-1,1,1,-1,-1,1,-1,-1,1,1,1,1,1,-1,1,1,-1,-1,-1,-1,-1,1,1,-1,-1,1,1,-1,1,-1,-1,-1,-1,-1,1,-1),(1,-1,1,-1,1,1,1,1,1,-1,-1,-1,1,-1,-1,1,-1,-1,-1,1,1,-1,-1,-1,1,1,1,-1,-1,1,-1,-1,-1,1,1,1,-1,-1,-1,-1,-1,1,1,1,-1,1,-1,-1,1,-1,-1),(-1,-1,-1,-1,1,1,1,-1,-1,-1,1,-1,1,1,-1,1,-1,1,1,-1,-1,-1,-1,-1,-1,1,-1,1,-1,1,-1,1,-1,-1,-1,-1,1,-1,-1,-1,-1,1,-1,1,1,1,-1,1,-1,1,-1),(-1,-1,-1,-1,-1,1,-1,1,1,1,-1,1,-1,1,1,-1,1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,-1,-1,-1,-1,-1,-1,-1,1,-1,1,-1,1,-1,-1,-1,-1,1,-1,1,1,-1,1,-1),(-1,-1,1,-1,-1,-1,1,1,-1,-1,1,1,-1,1,-1,1,1,1,1,-1,-1,-1,-1,-1,1,1,1,1,1,-1,-1,1,1,1,-1,-1,-1,1,-1,1,-1,-1,-1,-1,-1,1,-1,1,1,1,-1),(-1,-1,1,1,1,-1,-1,1,1,-1,-1,-1,1,-1,-1,1,1,-1,-1,1,1,-1,-1,-1,1,1,-1,-1,1,1,-1,1,1,-1,-1,1,-1,1,-1,-1,-1,-1,-1,1,-1,-1,-1,1,-1,1,1),(-1,-1,1,-1,-1,-1,1,-1,-1,-1,1,-1,1,1,-1,1,1,-1,-1,1,1,-1,1,-1,1,1,-1,1,1,-1,-1,-1,-1,-1,1,-1,1,1,-1,1,-1,1,-1,1,-1,-1,1,1,1,1,-1),(-1,-1,1,-1,-1,-1,1,1,1,1,1,-1,-1,1,1,-1,1,-1,-1,-1,1,1,-1,1,1,-1,-1,-1,1,-1,-1,1,-1,-1,-1,1,-1,1,1,1,-1,-1,1,1,-1,-1,-1,1,1,1,1),(-1,-1,1,-1,1,-1,-1,1,-1,-1,1,1,1,1,-1,1,1,-1,-1,-1,1,1,-1,1,-1,1,-1,1,-1,-1,-1,1,-1,-1,-1,-1,1,1,-1,1,-1,-1,1,1,-1,-1,-1,1,1,1,-1),(-1,-1,1,-1,1,-1,-1,-1,1,1,-1,-1,-1,-1,1,1,1,-1,-1,-1,1,-1,1,1,-1,1,-1,1,1,-1,-1,-1,-1,1,1,-1,-1,1,-1,1,-1,-1,1,-1,-1,1,1,1,1,1,-1),(-1,-1,1,-1,1,1,1,-1,-1,1,-1,1,1,1,-1,1,1,-1,-1,-1,1,-1,1,-1,-1,-1,-1,1,-1,-1,-1,1,1,-1,-1,-1,-1,1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1,-1),(-1,-1,1,-1,1,-1,-1,1,-1,-1,-1,1,1,-1,1,1,1,-1,-1,1,1,-1,-1,1,1,1,1,1,-1,-1,-1,1,-1,-1,-1,1,-1,1,-1,1,-1,-1,1,1,1,-1,1,1,1,1,1),(-1,-1,1,-1,1,-1,1,1,-1,-1,-1,-1,1,1,1,1,1,-1,-1,1,1,1,-1,1,-1,-1,-1,1,1,-1,-1,1,1,1,1,-1,1,1,-1,1,-1,-1,-1,-1,-1,-1,1,1,1,-1,-1),(-1,-1,1,1,-1,1,-1,1,-1,-1,-1,-1,1,1,-1,-1,1,1,-1,-1,-1,-1,1,-1,1,1,1,1,1,-1,-1,1,1,1,1,1,1,1,-1,1,-1,-1,-1,-1,-1,1,1,1,1,1,1),(-1,-1,1,-1,-1,-1,-1,1,-1,-1,-1,1,1,1,1,1,1,-1,-1,-1,-1,-1,-1,1,1,1,-1,1,-1,-1,-1,-1,-1,-1,1,-1,1,1,1,-1,-1,-1,1,1,1,1,-1,1,1,-1,-1),(-1,-1,1,1,1,-1,1,1,-1,-1,-1,-1,-1,-1,-1,1,1,1,-1,-1,-1,1,-1,-1,-1,1,1,1,-1,-1,-1,1,-1,1,1,1,-1,1,1,1,-1,1,-1,-1,-1,-1,-1,1,1,1,1),(-1,1,1,1,-1,1,-1,-1,-1,1,-1,1,-1,-1,-1,1,1,1,-1,1,1,-1,1,-1,1,1,1,-1,1,-1,-1,1,-1,1,-1,-1,1,1,1,1,-1,-1,1,-1,-1,-1,1,1,-1,1,1),(-1,-1,1,-1,1,-1,-1,1,-1,1,1,-1,-1,-1,-1,1,-1,-1,-1,1,-1,-1,-1,1,1,-1,-1,-1,1,-1,-1,1,-1,-1,1,1,1,1,1,-1,-1,-1,1,-1,-1,1,-1,1,-1,1,1),(1,-1,1,-1,1,-1,1,-1,1,1,1,1,1,1,-1,1,-1,1,-1,-1,-1,-1,-1,1,-1,1,1,1,-1,-1,1,-1,1,-1,-1,1,-1,-1,-1,-1,1,-1,-1,1,1,-1,-1,1,1,-1,1),(1,-1,1,1,-1,1,-1,-1,1,-1,1,1,1,1,1,1,1,1,-1,-1,-1,-1,1,-1,1,1,1,1,1,-1,-1,-1,-1,-1,1,1,-1,-1,-1,1,1,1,-1,1,1,-1,-1,-1,1,-1,1),(1,-1,-1,1,1,1,1,1,1,1,1,1,1,-1,1,1,1,1,-1,-1,1,1,-1,1,-1,-1,-1,-1,-1,1,-1,1,1,-1,1,1,-1,-1,1,-1,-1,-1,1,1,1,1,-1,-1,-1,1,-1),(1,-1,1,1,1,1,-1,1,1,-1,1,1,1,1,1,1,1,-1,-1,-1,-1,-1,-1,1,1,1,-1,1,1,-1,-1,-1,-1,-1,-1,1,-1,-1,1,1,-1,-1,1,1,1,-1,1,-1,-1,1,-1),(1,-1,-1,-1,1,-1,-1,-1,1,1,1,1,1,-1,-1,1,-1,1,-1,-1,1,-1,-1,1,1,-1,-1,-1,1,-1,1,1,1,-1,1,1,-1,-1,-1,1,-1,1,1,1,1,-1,-1,-1,1,1,1),(1,-1,1,1,-1,-1,-1,-1,1,-1,-1,1,1,-1,-1,-1,1,1,-1,-1,-1,-1,-1,1,-1,1,1,1,1,1,-1,-1,-1,1,-1,1,1,-1,1,-1,-1,-1,1,-1,-1,1,1,-1,-1,-1,1),(1,-1,-1,1,1,1,1,-1,1,-1,-1,1,-1,1,-1,1,1,1,-1,1,-1,-1,1,-1,-1,1,-1,-1,1,-1,-1,1,-1,-1,1,1,-1,1,-1,-1,-1,1,-1,1,-1,-1,1,-1,1,-1,1),(1,-1,1,1,-1,1,1,1,1,1,1,1,-1,1,-1,-1,-1,1,-1,-1,-1,-1,1,1,1,1,1,-1,1,1,-1,1,-1,-1,1,1,-1,1,-1,-1,-1,1,-1,-1,1,1,-1,-1,-1,1,1),(1,-1,-1,-1,-1,1,-1,1,1,-1,-1,1,-1,1,1,1,1,1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,1,1,-1,-1,-1,-1,1,-1,1,-1,-1,-1,-1,-1,-1,1,1,1,1,-1,1,1,1),(1,-1,-1,-1,1,-1,-1,-1,1,-1,1,1,1,1,1,1,1,1,-1,1,-1,1,1,-1,1,-1,1,1,1,1,-1,-1,-1,1,-1,1,1,-1,-1,-1,-1,-1,1,-1,1,1,1,-1,-1,1,1),(1,-1,-1,1,1,-1,1,-1,1,1,1,1,1,-1,-1,1,1,1,-1,1,1,1,-1,1,1,1,1,1,1,-1,-1,1,-1,-1,1,1,-1,-1,1,1,-1,1,1,1,1,-1,-1,-1,-1,1,-1),(1,-1,-1,-1,-1,1,1,1,1,-1,1,1,-1,-1,1,1,1,-1,-1,1,-1,-1,-1,1,1,-1,1,1,1,1,-1,1,1,-1,1,1,-1,-1,1,1,1,1,-1,1,1,1,1,1,1,1,1),(1,-1,-1,1,1,1,1,-1,1,-1,1,1,-1,1,-1,-1,-1,-1,-1,1,-1,1,-1,-1,1,1,1,-1,1,-1,-1,-1,1,-1,1,1,1,1,1,1,-1,1,-1,1,1,-1,-1,-1,-1,-1,-1),(1,-1,-1,1,-1,-1,-1,-1,1,-1,1,1,-1,-1,-1,1,1,-1,-1,-1,-1,-1,1,1,1,-1,-1,1,-1,-1,-1,1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,1,1,1,-1,-1,-1,-1,1),(1,-1,-1,-1,1,-1,-1,1,1,1,-1,1,1,1,-1,-1,1,1,-1,-1,-1,1,-1,-1,-1,-1,1,-1,-1,1,-1,-1,-1,-1,1,1,-1,1,1,1,1,-1,-1,1,1,-1,-1,-1,1,1,-1),(-1,1,1,1,1,-1,1,-1,1,-1,1,1,-1,-1,-1,-1,1,-1,-1,-1,1,-1,1,1,1,-1,1,1,-1,1,-1,1,1,1,1,1,-1,-1,-1,1,1,-1,-1,-1,1,1,-1,-1,1,-1,-1),(1,1,-1,-1,1,-1,-1,1,1,-1,-1,-1,1,-1,1,-1,1,-1,1,-1,1,-1,1,-1,-1,-1,1,1,1,1,-1,1,-1,-1,-1,-1,-1,-1,1,1,1,-1,-1,1,-1,1,-1,1,-1,-1,1),(-1,1,-1,-1,-1,1,-1,-1,1,-1,1,-1,1,-1,-1,-1,-1,-1,-1,-1,-1,-1,1,-1,-1,-1,1,-1,-1,1,1,-1,1,1,-1,1,-1,1,1,1,1,-1,1,1,-1,-1,-1,1,-1,-1,1),(-1,1,-1,-1,-1,-1,1,-1,1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,1,-1,1,-1,1,1,-1,1,1,1,1,1,-1,-1,-1,-1,-1,1,-1,1,1,1,-1,-1,1,1,1,-1,1,1,-1,1),(1,1,-1,-1,-1,1,1,1,1,-1,1,-1,1,-1,-1,1,1,-1,1,-1,-1,1,1,-1,1,-1,1,1,1,1,1,1,1,-1,-1,-1,-1,1,-1,1,1,-1,1,-1,-1,1,-1,-1,1,-1,1),(1,1,-1,-1,1,1,-1,-1,-1,-1,-1,-1,1,-1,-1,-1,-1,-1,1,1,-1,1,-1,-1,-1,-1,1,1,1,1,1,1,1,1,-1,1,1,-1,1,1,1,-1,-1,-1,-1,1,-1,-1,1,-1,-1),(1,1,1,-1,-1,1,1,-1,-1,-1,-1,-1,1,1,-1,-1,-1,-1,-1,1,1,-1,-1,-1,-1,-1,1,1,1,1,1,1,1,1,-1,1,1,-1,-1,1,1,-1,-1,-1,-1,1,-1,1,-1,1,1),(1,1,1,-1,-1,-1,1,1,1,1,-1,-1,1,1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,1,-1,-1,1,1,-1,1,1,1,-1,1,1,1,-1,1,1,-1,-1,-1,-1,1,-1,-1,-1,-1,-1,1),(1,1,-1,-1,-1,-1,-1,-1,-1,1,1,1,-1,-1,-1,-1,-1,-1,-1,1,-1,1,-1,1,-1,-1,1,1,1,1,1,-1,1,1,1,-1,-1,-1,1,1,1,-1,-1,1,-1,-1,-1,-1,1,1,-1),(-1,1,-1,1,-1,-1,1,1,1,-1,-1,1,1,-1,-1,-1,1,-1,-1,1,-1,-1,1,-1,1,-1,-1,-1,1,1,1,1,1,1,1,1,-1,-1,1,1,-1,1,-1,-1,-1,1,-1,-1,-1,-1,-1),(-1,1,1,-1,1,-1,1,-1,1,-1,-1,-1,1,-1,-1,-1,1,-1,1,-1,-1,1,-1,-1,1,-1,-1,1,1,1,-1,-1,1,1,1,-1,-1,-1,-1,1,1,-1,-1,-1,-1,1,-1,-1,1,1,1),(1,1,1,1,-1,1,-1,1,-1,-1,-1,1,1,-1,-1,-1,1,-1,1,1,1,-1,1,1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1,-1,-1,-1,-1,-1,-1,-1,1,1,-1,-1,-1,-1,1),(-1,1,-1,-1,-1,-1,1,1,1,-1,-1,-1,1,-1,-1,-1,-1,-1,-1,1,1,-1,1,-1,1,-1,1,1,-1,1,1,1,1,-1,1,1,-1,-1,-1,1,1,-1,1,-1,-1,1,-1,1,-1,-1,-1),(1,1,-1,-1,-1,-1,1,-1,1,-1,1,1,-1,-1,1,-1,-1,-1,1,-1,-1,-1,1,-1,1,-1,1,-1,1,1,1,1,1,1,1,1,1,-1,1,1,1,-1,1,-1,-1,1,-1,-1,-1,-1,1),(-1,1,-1,-1,-1,1,1,-1,1,-1,1,-1,-1,1,-1,-1,1,-1,-1,1,1,-1,1,-1,1,-1,-1,-1,1,1,1,1,-1,-1,-1,1,-1,-1,1,1,-1,-1,1,1,1,-1,-1,1,1,-1,1),(-1,1,1,1,1,1,-1,1,-1,1,-1,1,1,1,-1,1,1,1,1,-1,1,1,-1,-1,-1,1,-1,1,-1,-1,1,1,-1,-1,-1,-1,1,-1,-1,1,1,-1,1,-1,1,-1,1,1,1,-1,-1),(-1,-1,1,1,1,1,1,1,-1,1,1,1,-1,1,-1,-1,1,1,1,-1,1,1,1,-1,1,-1,-1,1,1,-1,-1,-1,-1,1,-1,-1,1,1,-1,1,1,-1,1,-1,1,-1,1,-1,1,1,-1),(-1,-1,1,1,1,1,1,1,-1,-1,-1,1,-1,-1,1,-1,1,1,1,-1,1,-1,1,1,-1,-1,-1,-1,-1,1,1,1,1,1,-1,-1,-1,1,-1,1,1,-1,1,1,1,-1,1,1,1,-1,1),(-1,-1,1,1,1,1,1,1,1,1,-1,1,-1,-1,1,1,1,1,1,1,1,1,-1,1,-1,-1,-1,1,1,1,1,-1,-1,-1,1,-1,1,-1,1,1,1,-1,-1,-1,1,1,1,1,1,1,-1),(-1,-1,1,1,1,1,-1,1,-1,1,1,1,1,-1,-1,1,1,1,1,-1,1,1,1,1,-1,-1,-1,1,-1,-1,-1,-1,1,1,-1,1,1,1,-1,-1,1,-1,1,1,1,1,1,1,1,1,-1),(-1,-1,1,1,-1,-1,1,1,-1,1,-1,1,-1,-1,1,1,1,1,1,-1,1,1,-1,-1,1,-1,-1,1,1,-1,1,1,-1,-1,-1,-1,1,1,1,-1,1,-1,1,-1,1,1,1,1,-1,-1,-1),(-1,1,-1,1,-1,1,-1,1,-1,1,1,1,-1,1,1,-1,1,1,1,-1,1,1,-1,1,-1,-1,-1,1,1,1,1,-1,-1,-1,-1,-1,1,1,1,-1,1,-1,1,-1,1,1,1,1,1,1,-1),(-1,-1,1,1,-1,-1,1,1,-1,1,-1,1,-1,1,1,-1,1,1,1,1,1,-1,-1,1,-1,-1,-1,1,-1,1,-1,1,-1,-1,-1,-1,1,-1,-1,-1,1,-1,1,1,1,-1,1,-1,1,1,1),(1,-1,-1,1,-1,1,-1,1,-1,1,-1,1,-1,-1,1,-1,1,1,1,1,1,1,-1,-1,-1,-1,1,1,1,1,1,1,-1,-1,1,-1,1,1,1,1,1,-1,1,1,1,-1,-1,-1,1,1,1),(-1,1,-1,1,-1,1,-1,1,-1,1,-1,1,-1,-1,1,1,1,1,1,-1,1,-1,-1,1,1,-1,-1,1,1,1,1,1,-1,-1,-1,1,1,-1,1,1,1,-1,-1,1,1,1,1,-1,1,1,-1),(-1,1,1,1,1,1,1,1,-1,-1,1,1,-1,1,-1,1,1,1,1,-1,1,-1,-1,-1,-1,-1,-1,1,1,1,1,1,1,-1,-1,-1,1,-1,-1,1,1,-1,-1,-1,1,-1,-1,1,1,1,1),(-1,1,-1,1,1,1,1,1,-1,1,1,1,-1,-1,1,1,1,1,1,-1,1,-1,-1,1,-1,-1,1,1,-1,1,1,-1,-1,1,-1,-1,1,1,1,1,1,1,-1,1,-1,-1,1,1,1,1,-1),(-1,1,1,1,1,1,1,1,-1,1,1,1,-1,1,1,1,1,1,-1,-1,1,1,-1,1,1,1,-1,1,1,1,1,1,-1,1,1,1,1,-1,-1,1,1,1,1,1,-1,-1,1,1,1,-1,-1),(-1,-1,1,1,1,1,1,1,-1,-1,-1,1,-1,-1,1,1,1,1,1,1,1,1,-1,-1,-1,-1,-1,1,1,1,1,-1,-1,-1,-1,-1,1,-1,-1,1,1,-1,-1,-1,1,1,1,-1,-1,-1,-1),(-1,1,1,1,1,1,1,1,-1,1,1,1,-1,-1,1,1,1,1,1,-1,1,-1,-1,1,-1,-1,-1,1,1,-1,1,1,-1,1,1,-1,1,1,-1,1,1,-1,1,-1,1,-1,1,1,1,-1,-1),(-1,1,-1,1,1,1,-1,1,1,1,1,-1,-1,-1,-1,-1,-1,-1,1,-1,-1,1,-1,1,-1,1,-1,1,1,1,-1,1,1,1,-1,1,-1,1,-1,-1,-1,1,-1,1,-1,1,1,-1,1,1,1),(-1,-1,-1,1,1,1,1,1,-1,1,-1,-1,1,-1,-1,-1,1,1,1,1,-1,1,1,1,-1,-1,-1,1,-1,1,-1,1,1,-1,-1,1,-1,-1,1,-1,-1,-1,-1,1,-1,1,1,-1,1,1,1),(-1,1,-1,1,1,-1,1,-1,1,1,-1,-1,1,1,-1,1,-1,1,1,-1,-1,1,-1,-1,-1,1,1,1,1,1,1,-1,-1,1,-1,-1,-1,-1,1,-1,1,1,-1,-1,-1,1,-1,1,1,1,1),(1,1,-1,1,1,-1,1,-1,1,1,1,-1,1,-1,-1,1,-1,1,-1,1,1,1,1,1,1,1,-1,1,-1,1,1,-1,-1,1,-1,-1,-1,-1,-1,1,-1,-1,-1,-1,-1,1,-1,-1,1,1,1),(-1,1,1,-1,1,1,-1,1,-1,1,-1,-1,1,-1,-1,-1,-1,-1,1,-1,-1,1,1,1,1,-1,1,1,1,1,1,1,1,1,-1,1,-1,-1,-1,1,-1,-1,-1,1,1,-1,-1,1,1,-1,1),(1,-1,-1,1,1,-1,1,-1,-1,-1,1,-1,-1,-1,1,1,-1,1,1,1,-1,1,-1,-1,-1,1,1,1,1,1,1,1,-1,1,1,-1,-1,1,-1,1,-1,1,-1,-1,-1,1,1,-1,-1,-1,-1),(-1,-1,-1,1,1,-1,1,-1,1,-1,-1,-1,1,1,-1,-1,-1,1,-1,-1,-1,1,-1,-1,1,1,-1,1,-1,1,-1,1,1,1,1,-1,-1,-1,1,-1,1,1,-1,1,1,-1,1,-1,-1,-1,1),(1,1,-1,1,1,-1,1,1,-1,1,-1,-1,1,1,-1,1,-1,1,-1,1,-1,1,-1,-1,-1,1,-1,1,1,1,1,1,1,1,-1,-1,1,-1,-1,-1,1,-1,-1,-1,1,1,-1,-1,1,-1,-1),(1,1,1,-1,1,-1,1,1,-1,1,1,-1,1,-1,-1,1,-1,-1,-1,-1,-1,1,1,-1,1,1,1,1,1,1,1,1,1,-1,1,-1,1,-1,-1,1,-1,1,-1,1,-1,1,1,-1,1,1,1),(-1,1,-1,1,1,-1,1,-1,-1,1,-1,-1,1,1,-1,1,-1,1,1,-1,-1,1,-1,-1,1,1,1,-1,1,1,1,-1,1,1,-1,-1,-1,-1,-1,-1,1,1,-1,-1,-1,1,1,-1,1,-1,1),(-1,1,-1,1,1,1,1,-1,1,1,-1,-1,-1,1,-1,1,-1,1,1,-1,-1,1,1,-1,1,1,-1,-1,1,1,-1,1,-1,-1,-1,1,1,-1,1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1),(-1,-1,1,-1,1,-1,-1,1,1,1,-1,-1,-1,-1,-1,-1,1,1,1,-1,-1,1,-1,-1,-1,1,1,-1,-1,1,-1,1,1,-1,-1,-1,-1,-1,-1,-1,1,1,-1,-1,-1,1,1,-1,-1,1,-1),(-1,-1,-1,-1,1,-1,-1,-1,-1,1,1,-1,-1,1,1,-1,-1,-1,1,-1,1,1,-1,-1,-1,1,-1,-1,-1,1,1,-1,1,1,-1,-1,1,1,1,-1,1,-1,-1,-1,-1,-1,1,-1,1,1,-1),(-1,1,-1,-1,1,-1,1,-1,-1,1,1,-1,-1,-1,-1,1,-1,1,1,1,1,1,-1,-1,1,1,-1,-1,-1,1,1,-1,1,-1,-1,-1,-1,-1,1,-1,1,1,-1,-1,1,1,1,-1,1,1,-1),(-1,1,-1,1,1,-1,1,1,-1,1,1,-1,-1,-1,-1,1,-1,-1,-1,-1,-1,1,-1,1,-1,1,1,1,-1,1,-1,1,1,-1,1,-1,-1,-1,1,-1,-1,1,-1,-1,-1,-1,1,-1,1,1,-1)):print(*r)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST 2 class\n",
        "train(BITS=51, CLASSES=2, validation_split=0.0, epochs=250, learning_rate=1e-4, patience=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DKY52vEefEK",
        "outputId": "4ed5872f-a2c2-4e27-80ee-d8f32b240745"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "371/371 [==============================] - 1s 1ms/step - loss: 0.5986 - accuracy: 0.6973\n",
            "Epoch 2/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.3819 - accuracy: 0.8415\n",
            "Epoch 3/250\n",
            "371/371 [==============================] - 1s 1ms/step - loss: 0.3092 - accuracy: 0.8980\n",
            "Epoch 4/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2834 - accuracy: 0.9188\n",
            "Epoch 5/250\n",
            "371/371 [==============================] - 1s 1ms/step - loss: 0.2693 - accuracy: 0.9266\n",
            "Epoch 6/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2571 - accuracy: 0.9352\n",
            "Epoch 7/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.9416\n",
            "Epoch 8/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.9435\n",
            "Epoch 9/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2399 - accuracy: 0.9480\n",
            "Epoch 10/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2352 - accuracy: 0.9504\n",
            "Epoch 11/250\n",
            "371/371 [==============================] - 1s 1ms/step - loss: 0.2347 - accuracy: 0.9521\n",
            "Epoch 12/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2309 - accuracy: 0.9537\n",
            "Epoch 13/250\n",
            "371/371 [==============================] - 1s 1ms/step - loss: 0.2295 - accuracy: 0.9528\n",
            "Epoch 14/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2296 - accuracy: 0.9541\n",
            "Epoch 15/250\n",
            "371/371 [==============================] - 1s 1ms/step - loss: 0.2305 - accuracy: 0.9510\n",
            "Epoch 16/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.9540\n",
            "Epoch 17/250\n",
            "371/371 [==============================] - 1s 1ms/step - loss: 0.2275 - accuracy: 0.9535\n",
            "Epoch 18/250\n",
            "371/371 [==============================] - 1s 2ms/step - loss: 0.2276 - accuracy: 0.9548\n",
            "Epoch 19/250\n",
            "371/371 [==============================] - 1s 2ms/step - loss: 0.2291 - accuracy: 0.9526\n",
            "Epoch 20/250\n",
            "371/371 [==============================] - 1s 2ms/step - loss: 0.2292 - accuracy: 0.9531\n",
            "Epoch 21/250\n",
            "371/371 [==============================] - 1s 1ms/step - loss: 0.2286 - accuracy: 0.9551\n",
            "Epoch 22/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.9508\n",
            "Epoch 23/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2289 - accuracy: 0.9546\n",
            "Epoch 24/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.9566\n",
            "Epoch 25/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9570\n",
            "Epoch 26/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2278 - accuracy: 0.9545\n",
            "Epoch 27/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2289 - accuracy: 0.9526\n",
            "Epoch 28/250\n",
            "371/371 [==============================] - 1s 1ms/step - loss: 0.2263 - accuracy: 0.9561\n",
            "Epoch 29/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.9533\n",
            "Epoch 30/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.9545\n",
            "Epoch 31/250\n",
            "371/371 [==============================] - 1s 1ms/step - loss: 0.2249 - accuracy: 0.9557\n",
            "Epoch 32/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2250 - accuracy: 0.9549\n",
            "Epoch 33/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.9542\n",
            "Epoch 34/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.9541\n",
            "Epoch 35/250\n",
            "371/371 [==============================] - 0s 1ms/step - loss: 0.2257 - accuracy: 0.9553\n",
            "for r in((1,-1,1,-1,1,-1,-1,-1,1,-1,-1,1,1,-1,-1,1,-1,1,1,-1,-1,-1,-1,1,1,-1,1,1,-1,-1,1,-1,-1,1,1,1,-1,1,1,-1,1,-1,-1,-1,1,1,1,1,-1,-1,-1),(1,-1,-1,-1,1,-1,-1,-1,1,1,1,1,1,-1,1,1,-1,1,1,-1,1,-1,-1,1,1,-1,1,-1,-1,-1,-1,1,-1,-1,-1,-1,1,1,1,1,-1,1,1,-1,1,-1,-1,-1,1,-1,-1),(1,1,1,-1,1,-1,-1,1,1,-1,-1,-1,1,1,-1,1,1,1,1,-1,1,1,1,-1,-1,1,-1,1,-1,1,-1,-1,1,1,1,-1,1,1,-1,-1,1,-1,-1,1,1,1,-1,-1,-1,1,-1),(1,1,1,-1,1,-1,-1,1,1,-1,-1,-1,-1,-1,1,-1,1,-1,1,-1,-1,1,1,-1,1,1,-1,1,1,1,1,-1,1,-1,-1,1,-1,-1,1,-1,1,-1,-1,1,1,-1,-1,1,-1,1,1),(-1,1,-1,-1,1,-1,-1,-1,-1,1,-1,-1,1,1,-1,-1,1,1,1,-1,1,-1,-1,1,-1,-1,-1,-1,-1,1,1,-1,1,1,-1,-1,-1,1,1,1,1,1,1,1,1,-1,-1,1,-1,-1,1),(1,1,-1,-1,-1,-1,-1,1,-1,1,1,1,-1,-1,1,-1,-1,-1,-1,-1,1,1,1,1,-1,1,-1,-1,1,-1,1,1,-1,1,1,-1,-1,1,1,1,1,-1,-1,-1,1,1,-1,1,-1,1,1),(-1,1,1,-1,1,-1,-1,-1,1,1,-1,1,1,-1,1,-1,1,-1,1,1,-1,-1,-1,1,1,1,1,-1,-1,-1,1,-1,1,-1,-1,1,1,1,1,-1,-1,-1,-1,-1,1,1,-1,-1,1,-1,1),(1,-1,1,-1,1,-1,-1,-1,1,1,1,-1,-1,-1,1,1,1,-1,1,-1,1,1,-1,1,1,-1,1,1,1,1,-1,1,1,-1,-1,1,1,-1,-1,-1,1,1,1,1,-1,1,1,-1,1,1,-1),(1,1,-1,-1,-1,-1,1,-1,1,1,1,-1,-1,-1,-1,1,1,1,-1,1,1,1,-1,-1,1,1,-1,-1,-1,-1,1,1,1,1,1,-1,-1,-1,-1,1,1,1,-1,1,-1,-1,-1,-1,-1,-1,-1),(-1,1,-1,-1,-1,-1,-1,1,1,1,1,1,-1,1,-1,1,-1,-1,1,1,1,-1,1,-1,1,1,-1,-1,1,1,1,-1,-1,1,1,-1,1,-1,-1,-1,-1,-1,1,-1,1,1,-1,-1,-1,-1,-1),(-1,1,1,-1,1,-1,-1,1,-1,-1,-1,1,1,1,-1,1,-1,1,-1,-1,-1,1,1,1,-1,1,1,1,-1,-1,1,-1,1,1,1,-1,1,-1,-1,-1,1,1,1,1,-1,-1,-1,-1,-1,1,-1),(-1,-1,1,-1,1,1,-1,1,1,-1,-1,1,-1,1,-1,1,-1,-1,1,-1,1,-1,-1,-1,1,1,-1,1,1,-1,-1,1,-1,1,-1,1,1,1,-1,-1,1,1,1,-1,-1,1,-1,1,1,1,1),(1,-1,1,-1,1,1,-1,-1,-1,-1,1,1,1,1,1,-1,-1,-1,1,-1,1,1,1,-1,1,-1,-1,1,-1,-1,1,-1,-1,1,-1,1,1,1,1,1,-1,1,1,1,1,-1,1,1,1,-1,1),(1,-1,1,-1,1,-1,1,-1,-1,1,-1,1,-1,1,1,-1,-1,1,1,1,-1,-1,1,-1,1,1,1,-1,-1,-1,-1,1,1,-1,1,1,1,1,-1,-1,1,1,1,-1,1,-1,1,-1,1,1,1),(1,1,-1,-1,-1,-1,-1,1,-1,1,1,1,-1,-1,1,-1,1,-1,-1,-1,-1,1,-1,1,-1,1,1,1,1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,-1,1,-1,-1,1,1,-1,1,1,1,-1),(1,1,1,1,1,1,-1,-1,-1,1,1,-1,-1,1,-1,1,1,1,-1,1,-1,-1,1,-1,1,-1,-1,1,1,1,1,1,-1,-1,-1,-1,-1,-1,-1,1,-1,1,-1,1,1,1,-1,-1,-1,1,-1),(-1,-1,-1,1,-1,1,1,-1,1,-1,-1,-1,-1,1,-1,1,1,-1,-1,1,1,-1,-1,1,-1,-1,1,-1,1,1,-1,-1,-1,1,1,1,-1,-1,1,1,-1,1,1,-1,-1,-1,1,-1,-1,-1,1),(-1,-1,-1,1,-1,1,1,1,-1,1,1,-1,1,1,1,-1,-1,-1,-1,-1,1,-1,-1,-1,1,-1,1,-1,1,1,-1,-1,1,1,-1,-1,1,-1,1,-1,1,-1,-1,-1,-1,1,1,1,1,1,-1),(-1,1,-1,1,1,1,1,1,-1,-1,1,-1,1,-1,-1,1,-1,1,-1,-1,-1,1,1,1,-1,1,-1,1,-1,1,-1,-1,1,1,-1,1,-1,1,1,-1,-1,-1,1,-1,-1,-1,1,1,-1,1,-1),(-1,-1,1,1,-1,-1,1,-1,-1,1,1,-1,-1,1,1,-1,1,1,1,1,-1,-1,-1,1,1,-1,-1,1,1,-1,-1,-1,-1,1,-1,-1,1,-1,-1,1,-1,-1,1,-1,1,-1,1,1,-1,-1,1),(-1,-1,-1,-1,-1,1,1,-1,1,-1,-1,-1,1,1,-1,1,1,-1,1,1,1,-1,-1,-1,1,-1,1,1,1,1,-1,1,1,-1,1,-1,-1,1,-1,1,-1,-1,-1,1,-1,-1,1,1,1,1,1),(1,-1,1,1,1,1,1,1,1,-1,1,1,-1,1,1,-1,1,-1,-1,1,-1,-1,1,1,-1,-1,-1,1,-1,-1,1,1,-1,1,1,1,-1,-1,-1,-1,-1,-1,-1,-1,-1,1,1,-1,1,-1,1),(-1,-1,1,1,-1,1,1,-1,-1,1,1,1,1,1,1,1,-1,1,-1,1,-1,1,1,-1,-1,1,1,-1,-1,-1,-1,1,1,1,1,-1,-1,-1,-1,-1,-1,-1,1,1,-1,-1,1,1,-1,-1,1),(1,-1,-1,1,-1,1,1,1,-1,-1,1,1,-1,-1,-1,-1,-1,1,-1,1,1,-1,-1,1,-1,1,-1,1,-1,1,-1,1,-1,-1,-1,1,-1,-1,1,-1,1,-1,1,1,-1,-1,-1,-1,1,-1,-1),(-1,1,1,1,-1,-1,1,1,1,-1,1,1,1,1,-1,-1,1,1,-1,1,-1,1,1,1,1,1,1,-1,1,1,-1,1,1,-1,-1,-1,-1,-1,1,1,1,1,-1,1,-1,-1,-1,-1,1,1,-1),(1,1,-1,1,-1,1,1,-1,1,-1,-1,1,-1,1,1,1,-1,-1,-1,1,1,-1,-1,1,-1,-1,1,-1,1,1,-1,-1,1,-1,1,-1,1,1,1,-1,-1,-1,-1,1,-1,1,1,1,-1,1,1),(1,-1,-1,1,-1,-1,1,1,-1,-1,-1,-1,-1,-1,1,1,-1,-1,-1,-1,1,-1,1,-1,1,-1,1,-1,-1,-1,-1,-1,1,-1,1,1,-1,1,-1,1,-1,-1,-1,-1,-1,1,1,1,1,-1,-1),(-1,-1,-1,1,-1,1,1,1,-1,1,-1,-1,1,1,-1,-1,1,-1,1,1,-1,-1,1,1,1,-1,-1,-1,1,1,1,1,-1,-1,1,1,1,-1,1,-1,-1,1,1,-1,1,-1,-1,-1,-1,-1,1),(-1,-1,1,1,1,1,-1,1,-1,-1,-1,1,1,-1,-1,-1,1,1,-1,1,-1,1,1,-1,-1,1,-1,1,-1,1,1,-1,-1,-1,-1,-1,-1,-1,1,1,-1,-1,-1,1,-1,1,1,1,1,-1,1),(-1,1,-1,1,-1,1,1,-1,1,1,-1,-1,1,-1,-1,-1,-1,1,-1,1,-1,1,-1,-1,-1,1,-1,-1,1,1,1,1,-1,1,1,1,1,1,-1,1,1,1,1,1,-1,1,1,-1,1,1,1)):print(*r)\n"
          ]
        }
      ]
    }
  ]
}